{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee3eb819-83ef-424a-a4e3-9828b6f48821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 75ms/step - accuracy: 0.4597 - loss: 1.1557 - val_accuracy: 0.5284 - val_loss: 1.0475\n",
      "Epoch 2/15\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 65ms/step - accuracy: 0.5676 - loss: 0.9852 - val_accuracy: 0.6075 - val_loss: 0.9202\n",
      "Epoch 3/15\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 63ms/step - accuracy: 0.6291 - loss: 0.8739 - val_accuracy: 0.6173 - val_loss: 0.8788\n",
      "Epoch 4/15\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 71ms/step - accuracy: 0.6471 - loss: 0.8212 - val_accuracy: 0.6418 - val_loss: 0.8493\n",
      "Epoch 5/15\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 67ms/step - accuracy: 0.6765 - loss: 0.7690 - val_accuracy: 0.6405 - val_loss: 0.8258\n",
      "Epoch 6/15\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 65ms/step - accuracy: 0.6955 - loss: 0.7260 - val_accuracy: 0.6545 - val_loss: 0.8171\n",
      "Epoch 7/15\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 64ms/step - accuracy: 0.7107 - loss: 0.6857 - val_accuracy: 0.6643 - val_loss: 0.8010\n",
      "Epoch 8/15\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 63ms/step - accuracy: 0.7336 - loss: 0.6432 - val_accuracy: 0.6688 - val_loss: 0.7869\n",
      "Epoch 9/15\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 67ms/step - accuracy: 0.7599 - loss: 0.5904 - val_accuracy: 0.6701 - val_loss: 0.8218\n",
      "Epoch 10/15\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 65ms/step - accuracy: 0.7699 - loss: 0.5665 - val_accuracy: 0.6793 - val_loss: 0.8057\n",
      "Epoch 11/15\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 79ms/step - accuracy: 0.7843 - loss: 0.5306 - val_accuracy: 0.6809 - val_loss: 0.8272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ System is active only between 9:30 AM to 10:00 AM.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 1. Load and preprocess FER2013 dataset from your custom path\n",
    "def load_emotion_dataset(data_dir=r'C:\\Users\\raaga\\OneDrive\\Desktop\\fer\\train', target_size=(48, 48)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_names = sorted(os.listdir(data_dir))\n",
    "    \n",
    "    for label in label_names:\n",
    "        label_dir = os.path.join(data_dir, label)\n",
    "        for file in os.listdir(label_dir):\n",
    "            img_path = os.path.join(label_dir, file)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, target_size)\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "\n",
    "    images = np.array(images, dtype=\"float32\") / 255.0\n",
    "    images = np.expand_dims(images, -1)\n",
    "    lb = LabelBinarizer()\n",
    "    labels = lb.fit_transform(labels)\n",
    "    return images, labels, lb.classes_\n",
    "\n",
    "X_emotion, y_emotion, emotion_labels = load_emotion_dataset()\n",
    "\n",
    "# 2. Train Emotion Classification Model\n",
    "X_train_em, X_val_em, y_train_em, y_val_em = train_test_split(X_emotion, y_emotion, test_size=0.2, random_state=42)\n",
    "\n",
    "model_emotion = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(emotion_labels), activation='softmax')\n",
    "])\n",
    "\n",
    "model_emotion.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(patience=3, restore_best_weights=True)\n",
    "model_emotion.fit(X_train_em, y_train_em, validation_data=(X_val_em, y_val_em), epochs=15, batch_size=64, callbacks=[early_stop])\n",
    "\n",
    "model_emotion.save(\"emotion_model.h5\")\n",
    "\n",
    "# 3. Load LFW dataset (3–5 students)\n",
    "lfw = fetch_lfw_people(min_faces_per_person=20, resize=0.4)\n",
    "student_names = list(np.unique(lfw.target_names))\n",
    "chosen_students = random.sample(student_names, 4)\n",
    "X_faces = []\n",
    "y_faces = []\n",
    "\n",
    "for i, name in enumerate(lfw.target_names):\n",
    "    if name in chosen_students:\n",
    "        X_faces.append(lfw.images[i])\n",
    "        y_faces.append(name)\n",
    "\n",
    "X_faces = np.array(X_faces)\n",
    "y_faces = np.array(y_faces)\n",
    "\n",
    "# 4. Train simple Face Recognition model\n",
    "X_faces_flatten = X_faces.reshape((X_faces.shape[0], -1))\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_faces_flatten, y_faces)\n",
    "\n",
    "# 5. Simulate attendance within 9:30–10:00 AM\n",
    "def simulate_attendance():\n",
    "    attendance = []\n",
    "    now = datetime.datetime.now()\n",
    "    current_time = now.time()\n",
    "    start_time = datetime.time(9, 30)\n",
    "    end_time = datetime.time(10, 0)\n",
    "\n",
    "    if not (start_time <= current_time <= end_time):\n",
    "        print(\"❌ System is active only between 9:30 AM to 10:00 AM.\")\n",
    "        return\n",
    "\n",
    "    for i in range(len(X_faces)):\n",
    "        face = X_faces[i]\n",
    "        name = y_faces[i]\n",
    "        face_flat = face.flatten().reshape(1, -1)\n",
    "\n",
    "        predicted_name = knn.predict(face_flat)[0]\n",
    "\n",
    "        # Predict emotion using trained model\n",
    "        face_resized = cv2.resize(face, (48, 48))\n",
    "        face_norm = face_resized.astype(\"float32\") / 255.0\n",
    "        face_input = np.expand_dims(face_norm, axis=(0, -1))\n",
    "        emotion_pred = model_emotion.predict(face_input)\n",
    "        emotion = emotion_labels[np.argmax(emotion_pred)]\n",
    "\n",
    "        attendance.append({\n",
    "            'Name': predicted_name,\n",
    "            'Time': now.strftime(\"%H:%M:%S\"),\n",
    "            'Status': 'Present',\n",
    "            'Emotion': emotion\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(attendance)\n",
    "    df.to_csv(\"attendance.csv\", index=False)\n",
    "    print(\"✅ Attendance saved to attendance.csv\")\n",
    "\n",
    "simulate_attendance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60297b4-1d68-4184-926e-a57f33ee1ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
